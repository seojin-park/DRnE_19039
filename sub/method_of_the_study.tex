\section{연구 과정}

\subsection{접근 가능한 데이터 확인}

해양위성센터, 공공데이터 포털, NASA Ocean Color Web 등에서 인공위성을 통해 수집한 SST 데이터를 다운받을 수 있다는 것을 확인하고, 접근 가능한 데이터를 연도와 센서별로 분류하여 \textrm{Table} \ref{Table:data}에 나타내었다.

\begin{center}
\begin{table}[h]
	\caption{다운 받을 수 있는 데이타}
	\begin{tabular}{c|c|c}
		\hline
		센서명          & 자료 시작 시기     & 자료 종료 시기 (2020. 4. 29. 기준) \\ \hline
		AVHRR        & 2011. 9. 1.  & 2020. 4. 21.               \\ \hline
		MODIS(Aqua)  & 2011. 9. 1.  & 2020. 4. 6.                \\ \hline
		MODIS(Terra) & 2011. 9. 1.  & 2020. 4. 7.                \\ \hline
		VIIRS        & 2016. 6. 17. & 2020. 4. 27.               \\ \hline
	\end{tabular}
	\label{Table:data}	
\end{table}
\end{center}
	
\subsection{데이터 크롤링}
Github에서 웹 크롤링 파일을 다운받고 그를 참고해 해양위성센터에서 받을 수 있는, 2012 년부터 2019 년까지의 8년 동안 Terra/Aqua 위성이 MODIS를 통해 수집한 SST데이터를 크롤링하는 코드를 만들었다. 아래는 소스코드이다. 


\lstset{basicstyle=\scriptsize, tabsize=4, numbers=left, keywordstyle=\color{blue}, commentstyle=\color{magenta}}

\begin{lstlisting}[language=python]
# Based on python2

import urllib.request as urllib
import os

# Example file path : 
# http://222.236.46.45/nfsdb/MODISA/2011/09/01/L2/MYDOCBOX.2011.0901.0413.aqua-1.hdf.zip
# http://222.236.46.45/nfsdb/MODIST/2011/09/01/L2/MODOCBOX.2011.0901.0235.terra-1.hdf.zip
# http://222.236.46.45/nfsdb/MODISA/2015/07/11/L2/MYDOCT.2015.0711.0457.aqua-1.hdf.zip
# http://222.236.46.45/nfsdb/MODIST/2011/09/03/L2/MODOCT.2011.0903.0222.terra-1.hdf.zip
# http://222.236.46.45/nfsdb/MODISA/2012/01/02/L2/MYDOCT.2012.01.02.0510.aqua-1.hdf.zip
#full_url = 'http://222.236.46.45/nfsdb/MODISA/2019/01/01/L2/MYDOCT.2019.0101.0000.aqua-1.hdf.zip'

save_dir_name = '../../downloads/'
if not os.path.exists(save_dir_name):
os.makedirs(save_dir_name)

url1 = 'http://222.236.46.45/nfsdb/MODIST'
url2 = 'terra-1.hdf.zip'

full_urls = []

for Yr in range(2012, 2020) :
	for Mo in range(1, 2) :
		for Da in range(1, 32) :
			for Ho in range(0, 24) :
				for Mi in range(0, 60) :
					full_urls.append("{0}/{1:04d}/{2:02d}/{3:02d}/L2/MODOCT.{1:04d}.{2:02d}{3:02d}.{4:02d}{5:02d}.{6}"\
						.format(url1, Yr, Mo, Da, Ho, Mi, url2))

for full_url in full_urls : 
	filename_el = full_url.split("/")
	filename = filename_el[-1]

	if not os.path.exists(filename) :
		try :
			urllib.urlretrieve(full_url, '{0}{1}'.format(save_dir_name, filename))
			print ('Trying {0}'.format(full_url), '{0}{1}\n'.format(save_dir_name, filename))
		except Exception as e: 
			print('error {0} : {1}\n'.format(e, filename))
	else :
		print ('{0} already exists\n'.format(filename))

\end{lstlisting}

\subsection{Ubuntu 환경}
Chrome Remote Desktop을 이용하여 개인 노트북을 통해 Ubuntu 운영체제의 서버 컴퓨터를 이용할 수 있도록 하였으며, 프롬프트에서 ls, cd 등 명령어를 사용하여 파일 디렉토리를 탐색하는 방법을 학습하였다. 많은 양의 데이터를 다운받아야 하기 때문에 도중에 프롬프트 창을 닫더라도 계속 다운받을 수 있도록 nohup 명령어를 이용하여 백그라운드로 파일을 실행하였다. 



